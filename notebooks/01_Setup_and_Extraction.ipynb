{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Configuração e Extração de Features\n",
    "\n",
    "Este notebook cobre a configuração inicial do ambiente (Google Colab ou Local), montagem do Google Drive, criação de dataset de exemplo e execução do pipeline de extração de características de áudio em lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuração do Ambiente\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def is_colab():\n",
    "    return 'google.colab' in sys.modules\n",
    "\n",
    "if is_colab():\n",
    "    print(\"Ambiente Google Colab detectado.\")\n",
    "    # Clone o repositório se não existir (ajuste a URL conforme necessário)\n",
    "    if not os.path.exists('/content/TCC'):\n",
    "        !git clone https://github.com/thieryw/TCC.git /content/TCC\n",
    "    \n",
    "    # Mudar diretório de trabalho\n",
    "    os.chdir('/content/TCC')\n",
    "    \n",
    "    # Instalar dependências\n",
    "    print(\"Instalando dependências...\")\n",
    "    !apt-get install -y ffmpeg\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install python-multipart\n",
    "    \n",
    "    # Adicionar ao path\n",
    "    sys.path.append('/content/TCC')\n",
    "else:\n",
    "    print(\"Ambiente Local detectado.\")\n",
    "    # Assumindo que você está na raiz do projeto\n",
    "    if os.path.exists('app'):\n",
    "        sys.path.append(os.getcwd())\n",
    "\n",
    "print(f\"Diretório atual: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Importações e Setup do Sistema\n",
    "from app.utils.colab import mount_drive, setup_colab_env\n",
    "from app.domain.services.feature_extraction_service import AudioFeatureExtractionService\n",
    "from app.domain.models.audio_data import AudioData\n",
    "from app.domain.models.extraction_config import ExtractionConfig\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "# Configurar ambiente Colab (se aplicável)\n",
    "setup_colab_env()\n",
    "mount_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aquisição e Preparação de Dados\n",
    "Vamos criar um dataset sintético para demonstração, organizado em pastas `real` e `fake`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_RAW_DIR = \"datasets/raw_sample\"\n",
    "\n",
    "def create_dummy_audio(filename, duration=1.0, sr=22050, freq=440):\n",
    "    t = np.linspace(0, duration, int(duration*sr))\n",
    "    y = np.sin(2*np.pi*freq*t)\n",
    "    sf.write(filename, y, sr)\n",
    "\n",
    "def create_dummy_dataset(base_dir, num_samples=10):\n",
    "    classes = ['real', 'fake']\n",
    "    for label in classes:\n",
    "        class_dir = os.path.join(base_dir, label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        for i in range(num_samples):\n",
    "            # Frequências diferentes para diferenciar classes visualmente nos features\n",
    "            freq = 440 if label == 'real' else 880 \n",
    "            filename = os.path.join(class_dir, f\"{label}_{i}.wav\")\n",
    "            if not os.path.exists(filename):\n",
    "                create_dummy_audio(filename, freq=freq)\n",
    "    print(f\"Dataset dummy criado em {base_dir}\")\n",
    "\n",
    "create_dummy_dataset(DATASET_RAW_DIR, num_samples=5)\n",
    "\n",
    "# Listar estrutura\n",
    "for root, dirs, files in os.walk(DATASET_RAW_DIR):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extração de Features em Lote\n",
    "Processar todo o dataset e preparar para treinamento (X, y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar serviço\n",
    "extractor_service = AudioFeatureExtractionService()\n",
    "print(\"Serviço de extração inicializado.\")\n",
    "\n",
    "# Configuração\n",
    "config = ExtractionConfig(\n",
    "    mfcc=True,\n",
    "    spectral_centroid=True,\n",
    "    chroma=True,\n",
    "    zero_crossing_rate=True\n",
    ")\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "classes = {'real': 0, 'fake': 1}\n",
    "\n",
    "print(\"Iniciando extração...\")\n",
    "\n",
    "for label_name, label_idx in classes.items():\n",
    "    class_dir = os.path.join(DATASET_RAW_DIR, label_name)\n",
    "    if not os.path.exists(class_dir): continue\n",
    "    \n",
    "    for file in os.listdir(class_dir):\n",
    "        if not file.endswith('.wav'): continue\n",
    "        \n",
    "        file_path = os.path.join(class_dir, file)\n",
    "        try:\n",
    "            # Carregar e extrair\n",
    "            audio_y, sr = librosa.load(file_path, sr=None, duration=3.0)\n",
    "            # Garantir tamanho fixo para CNN simples (pad ou truncate)\n",
    "            # Vamos fixar em ~128 frames para MFCC (aprox 3s)\n",
    "            target_len = 22050 * 3 # 3 segundos\n",
    "            if len(audio_y) < target_len:\n",
    "                audio_y = np.pad(audio_y, (0, target_len - len(audio_y)))\n",
    "            else:\n",
    "                audio_y = audio_y[:target_len]\n",
    "                \n",
    "            audio_data = AudioData(audio=audio_y, sample_rate=sr)\n",
    "            result = extractor_service.extract_features(audio_data, config)\n",
    "            \n",
    "            # Usar MFCC como feature principal para este exemplo\n",
    "            # Shape típico: (n_mfcc, time_steps)\n",
    "            feature = result.features.get('mfcc')\n",
    "            \n",
    "            if feature is not None:\n",
    "                # Transpor para (time, n_mfcc) se necessário ou manter para CNN 2D\n",
    "                # Vamos manter (n_mfcc, time) que é (20, 130) aprox\n",
    "                # Ajustar shape para consistência exata\n",
    "                desired_shape = (20, 130)\n",
    "                if feature.shape[1] > desired_shape[1]:\n",
    "                    feature = feature[:, :desired_shape[1]]\n",
    "                elif feature.shape[1] < desired_shape[1]:\n",
    "                    feature = np.pad(feature, ((0,0), (0, desired_shape[1] - feature.shape[1])))\n",
    "                \n",
    "                X.append(feature)\n",
    "                y.append(label_idx)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erro em {file}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"Extração concluída. X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualização e Salvamento\n",
    "Salvar o dataset processado no formato .npz para o notebook de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir em treino e validação (simples)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if len(X) > 0:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    OUTPUT_DIR = \"datasets/processed\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    output_path = os.path.join(OUTPUT_DIR, \"dataset_processed.npz\")\n",
    "    np.savez(output_path, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "    print(f\"Dataset salvo em: {output_path}\")\n",
    "    \n",
    "    # Copiar para o Drive\n",
    "    if is_colab() and os.path.exists('/content/drive/MyDrive'):\n",
    "        DRIVE_PATH = \"/content/drive/MyDrive/TCC_Features\"\n",
    "        os.makedirs(DRIVE_PATH, exist_ok=True)\n",
    "        import shutil\n",
    "        shutil.copy(output_path, DRIVE_PATH)\n",
    "        print(f\"Copiado para o Drive: {DRIVE_PATH}\")\n",
    "else:\n",
    "    print(\"Nenhum dado extraído.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}