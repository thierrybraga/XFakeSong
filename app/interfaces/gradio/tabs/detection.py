import gradio as gr
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
import librosa
import librosa.display
import json
import logging
from pathlib import Path
import sys

from app.core.interfaces.audio import AudioData

# Configurar logging
logger = logging.getLogger("gradio_detection_tab")

# Singleton para o servi√ßo de detec√ß√£o
_detection_service_instance = None

def get_detection_service():
    global _detection_service_instance
    if _detection_service_instance is None:
        try:
            from app.domain.services.detection_service import DetectionService
            # Inicializa com diret√≥rio padr√£o 'models'
            _detection_service_instance = DetectionService()
        except Exception as e:
            logger.error(f"Failed to init detection service: {e}")
            return None
    return _detection_service_instance

# Tentar importar servi√ßos
try:
    from app.domain.services.detection_service import DetectionService
    from app.domain.models.architectures.registry import get_architecture_info, get_available_architectures
    MODELS_AVAILABLE = True
except ImportError as e:
    logger.warning(
        f"Aviso: N√£o foi poss√≠vel importar servi√ßos de detec√ß√£o ({e}). Usando modo demonstra√ß√£o.")
    MODELS_AVAILABLE = False


def get_waveform_plot(y, sr):
    """Gera plot da forma de onda."""
    plt.figure(figsize=(10, 3))
    librosa.display.waveshow(y, sr=sr, alpha=0.8)
    plt.title("Forma de Onda")
    plt.tight_layout()
    return plt.gcf()


def get_prosody_plot(y, sr):
    """Gera plot de pros√≥dia (F0 e Energia)."""
    plt.figure(figsize=(10, 4))

    # Energia
    rms = librosa.feature.rms(y=y)[0]
    times = librosa.times_like(rms)
    plt.plot(times, rms, label='Energia (RMS)', color='r', alpha=0.6)

    # F0 (Pitch)
    try:
        f0, voiced_flag, voiced_probs = librosa.pyin(
            y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))
        times_f0 = librosa.times_like(f0)

        # Normalizar F0 para plotar junto
        if np.nanmax(f0) > 0:
            f0_norm = f0 / np.nanmax(f0)
            plt.plot(
                times_f0,
                f0_norm,
                label='Pitch (F0 Normalizado)',
                color='b',
                alpha=0.6)
    except Exception as e:
        logger.warning(f"Erro ao calcular Pitch: {e}")

    plt.legend()
    plt.title("An√°lise Pros√≥dica: Energia e Pitch")
    plt.xlabel("Tempo (s)")
    plt.tight_layout()

    return plt.gcf()


def get_spectrogram_plot(y, sr):
    """Gera espectrograma Mel."""
    plt.figure(figsize=(10, 4))
    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
    S_dB = librosa.power_to_db(S, ref=np.max)
    librosa.display.specshow(
        S_dB,
        x_axis='time',
        y_axis='mel',
        sr=sr,
        fmax=8000)
    plt.colorbar(format='%+2.0f dB')
    plt.title("Espectrograma Mel")
    plt.tight_layout()
    return plt.gcf()


def analyze_audio(audio_path, architecture, variant,
                  advanced_enabled, hyperparams_json, segmented):
    if not audio_path:
        return "Erro: Nenhum √°udio fornecido.", 0.0, None, None, {}

    try:
        # Carregar √°udio para visualiza√ß√£o
        y, sr = librosa.load(audio_path, sr=16000)

        # Gerar plots
        fig_waveform = get_waveform_plot(y, sr)
        fig_prosody = get_prosody_plot(y, sr)
        fig_spectrogram = get_spectrogram_plot(y, sr)

        # Detec√ß√£o
        result_label = "DESCONHECIDO"
        confidence = 0.0
        details = {}

        if MODELS_AVAILABLE:
            try:
                service = get_detection_service()
                if not service:
                    raise Exception("Servi√ßo de detec√ß√£o n√£o inicializado")
                
                model_name = None

                # Sele√ß√£o de Modelo
                if advanced_enabled and architecture:
                    # Tentar encontrar modelo compat√≠vel com a arquitetura/variante
                    model_name = service.find_model(architecture, variant=variant)
                    if not model_name:
                         # Fallback: Tentar qualquer modelo dessa arquitetura
                        models = service.get_available_models()
                        for m in models:
                            if architecture in m: # Heur√≠stica simples
                                model_name = m
                                break
                    
                    if not model_name:
                         logger.warning(f"Nenhum modelo encontrado para {architecture}/{variant}")
                         # N√£o falha aqui, deixa o service usar o default se passar None, 
                         # ou retornar√° erro se n√£o houver default.
                else:
                    # Modo simples: usa o default do service ou o primeiro dispon√≠vel
                    model_name = service.default_model
                    if not model_name:
                        models = service.get_available_models()
                        if models:
                            model_name = models[0]

                if not model_name:
                    return "MODELO N√ÉO ENCONTRADO", 0.0, fig_waveform, fig_prosody, fig_spectrogram, {"error": "Nenhum modelo treinado dispon√≠vel. Treine um modelo na aba de Treinamento."}

                # Executar Detec√ß√£o
                result_proc = service.detect_from_file(
                    audio_path, 
                    model_name=model_name, 
                    segmented=bool(segmented)
                )

                if result_proc.status.name == "SUCCESS":
                    data = result_proc.data
                    result_label = "DEEPFAKE" if data.is_fake else "REAL"
                    confidence = float(data.confidence)
                    details = {
                        "model": data.model_name,
                        "probabilities": data.probabilities,
                        "metadata": data.metadata,
                        "features_used": data.features_used
                    }
                    
                    # Persistir Resultado (usando o servi√ßo)
                    filename = Path(audio_path).name if audio_path else "unknown.wav"
                    service.save_analysis_result(data, filename)
                    
                else:
                    details = {
                        "error": result_proc.errors[0] if result_proc.errors else "Erro na infer√™ncia"
                    }
                    logger.error(f"Erro na infer√™ncia: {details['error']}")

            except Exception as e:
                logger.error(f"Erro na infer√™ncia: {e}")
                details = {"erro_inferencia": str(e)}

        # Mock de fallback (apenas se realmente falhou tudo)
        if result_label in ["MODELO N√ÉO ENCONTRADO", "DESCONHECIDO"] and not details.get("error"):
            result_label = "DEMO MODE (Sem Modelo)"
            confidence = 0.0

        # Detalhes t√©cnicos adicionais
        details["audio_info"] = {
            "duration": float(len(y) / sr),
            "sample_rate": sr,
            "rms_mean": float(np.mean(librosa.feature.rms(y=y)))
        }

        return result_label, confidence, fig_waveform, fig_prosody, fig_spectrogram, json.dumps(details, indent=2)

    except Exception as e:
        return f"Erro: {str(e)}", 0.0, None, None, None, {"error": str(e)}

    except Exception as e:
        return f"Erro: {str(e)}", 0.0, None, None, {"error": str(e)}


def process_stream(new_chunk, state):
    """Processamento em tempo real do stream de √°udio com detec√ß√£o cont√≠nua."""
    try:
        if new_chunk is None:
            return state, gr.update(), gr.update(), gr.update(), gr.update(), gr.update()

        sr, data = new_chunk

        # Inicializar estado
        if state is None:
            state = {
                "audio": np.array([], dtype=np.float32), 
                "sr": sr,
                "last_update": 0
            }

        # Converter e normalizar
        if data.dtype == np.int16:
            data = data.astype(np.float32) / 32768.0
        elif data.dtype == np.int32:
            data = data.astype(np.float32) / 2147483648.0

        # Converter est√©reo para mono
        if data.ndim > 1:
            data = np.mean(data, axis=1)

        # Acumular
        state["audio"] = np.concatenate((state["audio"], data))

        # Otimiza√ß√£o: Gerar plots apenas se tiver dados suficientes e n√£o for muito frequente
        y = state["audio"]

        if len(y) < sr * 0.1:  # Menos de 0.1s
            return state, gr.update(), gr.update(), gr.update(), gr.update(), gr.update()
            
        # Throttling: Atualizar visualiza√ß√£o no m√°ximo a cada 0.5s (2 FPS)
        # Isso evita sobrecarregar a fila e o navegador (causa de AbortError)
        import time
        current_time = time.time()
        if current_time - state.get("last_update", 0) < 0.5:
            return state, gr.update(), gr.update(), gr.update(), gr.update(), gr.update()
            
        state["last_update"] = current_time

        # Gerar plots r√°pidos
        # 0. Forma de Onda (Janela deslizante de 5s)
        fig_wave = Figure(figsize=(10, 3))
        ax_wave = fig_wave.add_subplot(111)
        
        # Limitar visualiza√ß√£o aos √∫ltimos 5 segundos
        window_size = sr * 5
        if len(y) > window_size:
            y_plot = y[-window_size:]
            x_start = (len(y) - window_size) / sr
        else:
            y_plot = y
            x_start = 0
            
        # Downsample para plotagem r√°pida (m√°x 2000 pontos)
        step = max(1, len(y_plot) // 2000)
        times_plot = np.linspace(x_start, x_start + len(y_plot)/sr, len(y_plot))[::step]
        y_plot_ds = y_plot[::step]
        
        ax_wave.plot(times_plot, y_plot_ds, alpha=0.8)
        ax_wave.set_title(f"Forma de Onda (Tempo Real)")
        ax_wave.set_ylim(-1.0, 1.0)
        fig_wave.tight_layout()

        # 1. Espectrograma Mel (mais r√°pido que o completo)
        fig_spec = Figure(figsize=(10, 4))
        ax_spec = fig_spec.add_subplot(111)

        # Usar n_fft menor para rapidez no stream?
        S = librosa.feature.melspectrogram(
            y=y, sr=sr, n_mels=64, hop_length=1024)
        S_dB = librosa.power_to_db(S, ref=np.max)
        img = librosa.display.specshow(
            S_dB,
            x_axis='time',
            y_axis='mel',
            sr=sr,
            fmax=8000,
            ax=ax_spec)
        fig_spec.colorbar(img, ax=ax_spec, format='%+2.0f dB')
        ax_spec.set_title(
            f"Espectrograma Mel (Tempo Real) - {len(y) / sr:.1f}s")
        fig_spec.tight_layout()

        # 2. Pros√≥dia (Energia + Pitch Simplificado)
        fig_pros = Figure(figsize=(10, 4))
        ax_pros = fig_pros.add_subplot(111)

        # Energia (RMS)
        rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=1024)[0]
        times = librosa.times_like(rms, sr=sr, hop_length=1024)
        ax_pros.plot(times, rms, label='Energia (RMS)', color='r', alpha=0.6)

        # Pitch (Estimativa r√°pida via Autocorrela√ß√£o para Real-time)
        try:
            # Calcular autocorrela√ß√£o apenas num frame recente para velocidade
            frame_len = int(sr * 0.05) # 50ms
            if len(y) > frame_len:
                y_frame = y[-frame_len:]
                
                # Autocorrela√ß√£o normalizada
                result = np.correlate(y_frame, y_frame, mode='full')
                result = result[len(result)//2:]
                
                # Encontrar pico entre lags correspondentes a 50Hz e 1000Hz
                min_lag = int(sr / 1000)
                max_lag = int(sr / 50)
                
                if len(result) > max_lag:
                    relevant = result[min_lag:max_lag]
                    if len(relevant) > 0:
                        lag = np.argmax(relevant) + min_lag
                        if result[lag] > 0.1 * result[0]: # Threshold de periodicidade
                            f0_est = sr / lag
                            # Plotar linha horizontal indicando F0 estimado atual
                            ax_pros.axhline(y=f0_est/1000, color='b', linestyle='--', alpha=0.5, label=f'Pitch Est. ({int(f0_est)}Hz)')
        except Exception:
            pass

        ax_pros.legend(loc='upper right')
        ax_pros.set_title(f"An√°lise Pros√≥dica: Energia (Tempo Real)")
        ax_pros.set_xlabel("Tempo (s)")
        fig_pros.tight_layout()

        # 3. Detec√ß√£o Real-time (Analise Acumulada)
        label_upd = gr.update()
        conf_upd = gr.update()

        # Executar detec√ß√£o se tiver pelo menos 0.5s de √°udio
        if len(y) > sr * 0.5:
            service = get_detection_service()
            if service:
                try:
                    # Cria AudioData com o buffer acumulado
                    audio_data = AudioData(
                        samples=y,
                        sample_rate=sr,
                        duration=float(len(y) / sr)
                    )
                    
                    res = service.detect_single(audio_data)
                    if res.status.name == "SUCCESS":
                        data_res = res.data
                        lbl = "DEEPFAKE" if data_res.is_fake else "REAL"
                        conf = float(data_res.confidence)

                        # Formato para Label output
                        label_upd = {lbl: conf, ("REAL" if lbl == "DEEPFAKE" else "DEEPFAKE"): 1.0 - conf}
                        conf_upd = conf
                except Exception as ex:
                    # Log menos verboso em stream
                    pass

        return state, fig_wave, fig_pros, fig_spec, label_upd, conf_upd

    except Exception as e:
        logger.error(f"Erro no stream: {e}")
        return state, gr.update(), gr.update(), gr.update(), gr.update(), gr.update()


def create_detection_tab():
    with gr.Tab("Detec√ß√£o (Inference)", id="tab_detection"):
        gr.Markdown("""
        ### üïµÔ∏è An√°lise de Integridade de √Åudio
        Fa√ßa upload de um arquivo de √°udio para verificar se ele √© aut√™ntico ou sint√©tico (DeepFake).
        """)

        with gr.Row():
            # Coluna de Entrada (Esquerda/Topo)
            with gr.Column(scale=1, min_width=500):
                with gr.Group():
                    gr.Markdown("#### üì• Entrada e Configura√ß√£o")
                    audio_input = gr.Audio(
                        type="numpy", label="Arquivo de √Åudio", sources=[
                            "upload", "microphone"], streaming=True)
                    stream_state = gr.State()

                    with gr.Accordion("‚öôÔ∏è Configura√ß√µes Avan√ßadas", open=False):

                        arch_choices = get_available_architectures() if MODELS_AVAILABLE else []
                        arch_select = gr.Dropdown(
                            choices=arch_choices,
                            label="Arquitetura do Modelo",
                            value=arch_choices[0] if arch_choices else None,
                        )
                        variant_select = gr.Dropdown(
                            choices=[], label="Variante", value=None)
                        advanced_enabled = gr.Checkbox(
                            label="Habilitar Par√¢metros Customizados", value=False)
                        hyperparams_json = gr.Code(
                            label="Hiperpar√¢metros (JSON)",
                            language="json",
                            value="{}",
                            interactive=True,
                            lines=3)
                        segmented_chk = gr.Checkbox(
                            label="Infer√™ncia Segmentada (Para √°udios longos)", value=False)

                    analyze_btn = gr.Button(
                        "üîç Analisar √Åudio", variant="primary", size="lg")

            # Coluna de Sa√≠da (Direita/Baixo)
            with gr.Column(scale=1, min_width=500):
                with gr.Group():
                    gr.Markdown("#### üìä Resultado da An√°lise")
                    with gr.Row():
                        label_output = gr.Label(
                            label="Classifica√ß√£o", num_top_classes=2, scale=2)
                        confidence_output = gr.Number(
                            label="Confian√ßa", scale=1)

        gr.Markdown("---")

        # Se√ß√£o de Detalhes Visuais (Full Width)
        gr.Markdown("### üìà Detalhes Forenses")
        
        plot_waveform = gr.Plot(label="Forma de Onda")
        
        with gr.Row():
            with gr.Column(min_width=400):
                plot_spectrogram = gr.Plot(label="Espectrograma Mel")
            with gr.Column(min_width=400):
                plot_prosody = gr.Plot(
                    label="An√°lise Pros√≥dica (Pitch/Energia)")

        with gr.Accordion("üìù Metadados T√©cnicos (JSON)", open=False):
            json_output = gr.JSON(label="Raw Output")

        def update_variants(arch_name):
            try:
                if MODELS_AVAILABLE and arch_name:
                    info = get_architecture_info(arch_name)

                    # Buscar default params do DB para exibir no JSON
                    from app.domain.models.architectures.registry import architecture_registry
                    params = architecture_registry.get_active_config(
                        arch_name, variant="default")

                    return gr.update(choices=info.supported_variants, value=(
                        info.supported_variants[0] if info.supported_variants else None)), json.dumps(params, indent=2)
            except Exception as e:
                logger.error(f"Erro ao atualizar variantes: {e}")
                pass
            return gr.update(choices=[], value=None), json.dumps({}, indent=2)

        arch_select.change(
            update_variants,
            inputs=[arch_select],
            outputs=[
                variant_select,
                hyperparams_json])

        # Limpar estado ao limpar √°udio
        def clear_state():
            return None

        audio_input.clear(
            fn=clear_state,
            inputs=None,
            outputs=[stream_state]
        )

        # Wrapper para lidar com upload vs stream
        def handle_analysis(audio_path, stream_state, architecture,
                            variant, advanced_enabled, hyperparams_json, segmented):
            import tempfile
            import soundfile as sf
            import numpy as np

            final_path = None

            # Handle numpy input (from upload/mic since type="numpy")
            if isinstance(audio_path, tuple):
                sr, data = audio_path
                try:
                    # Save to temp file
                    temp_file = tempfile.NamedTemporaryFile(
                        suffix=".wav", delete=False)
                    temp_file.close()
                    
                    # Convert to float32 if needed
                    if data.dtype == np.int16:
                        data = data.astype(np.float32) / 32768.0
                    elif data.dtype == np.int32:
                        data = data.astype(np.float32) / 2147483648.0
                        
                    sf.write(temp_file.name, data, sr)
                    final_path = temp_file.name
                    logger.info(f"√Åudio convertido de numpy para: {final_path}")
                except Exception as e:
                    return f"Erro ao processar √°udio: {str(e)}", 0.0, None, None, {"error": str(e)}
            elif isinstance(audio_path, str) and audio_path:
                final_path = audio_path

            # Se n√£o h√° path (ex: microfone stream) mas tem estado acumulado
            if not final_path and stream_state is not None and len(
                    stream_state.get("audio", [])) > 0:
                try:
                    # Salvar √°udio do estado em arquivo tempor√°rio
                    temp_file = tempfile.NamedTemporaryFile(
                        suffix=".wav", delete=False)
                    temp_file.close()

                    sr = stream_state.get("sr", 16000)
                    audio_data = stream_state["audio"]

                    sf.write(temp_file.name, audio_data, sr)
                    final_path = temp_file.name
                    logger.info(
                        f"Usando √°udio do stream salvo em: {final_path}")
                except Exception as e:
                    logger.error(f"Erro ao salvar stream para an√°lise: {e}")
                    return f"Erro ao processar grava√ß√£o: {str(e)}", 0.0, None, None, {
                        "error": str(e)}

            return analyze_audio(final_path, architecture, variant,
                                 advanced_enabled, hyperparams_json, segmented)

        analyze_btn.click(
            handle_analysis,
            inputs=[
                audio_input,
                stream_state,
                arch_select,
                variant_select,
                advanced_enabled,
                hyperparams_json,
                segmented_chk],
            outputs=[
                label_output,
                confidence_output,
                plot_waveform,
                plot_prosody,
                plot_spectrogram,
                json_output]
        )

        # Eventos de Streaming (Real-time)
        audio_input.stream(
            fn=process_stream,
            inputs=[audio_input, stream_state],
            outputs=[stream_state, plot_waveform, plot_prosody,
                     plot_spectrogram, label_output, confidence_output],
            show_progress="hidden"
        )
