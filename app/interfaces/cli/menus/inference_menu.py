from pathlib import Path
from app.interfaces.cli.menus.base_menu import BaseMenu


class InferenceMenu(BaseMenu):
    """Menu para infer√™ncia de √°udio."""

    def show(self):
        while True:
            print("\nüîç INFER√äNCIA DE √ÅUDIO")
            print("-" * 40)
            print("1. Analisar arquivo de √°udio")
            print("2. An√°lise em lote")
            print("3. Voltar ao menu principal")

            choice = input("\nEscolha uma op√ß√£o: ").strip()

            if choice == "1":
                self.analyze_single_audio()
            elif choice == "2":
                self.analyze_batch_audio()
            elif choice == "3":
                break
            else:
                print("‚ùå Op√ß√£o inv√°lida!")

    def analyze_single_audio(self):
        """Analisa um √∫nico arquivo de √°udio."""
        print("\nüéµ An√°lise de Arquivo √önico")

        model_files = list(self.context.models_dir.glob("*.h5"))
        if not model_files:
            print("‚ùå Nenhum modelo treinado encontrado.")
            return

        print("\nModelos dispon√≠veis:")
        for i, model_file in enumerate(model_files, 1):
            print(f"{i:2d}. {model_file.stem}")

        try:
            choice_input = input("\nEscolha um modelo (n√∫mero): ").strip()
            if not choice_input.isdigit():
                print("‚ùå Entrada inv√°lida!")
                return

            choice = int(choice_input) - 1
            if choice < 0 or choice >= len(model_files):
                print("‚ùå Escolha inv√°lida!")
                return

            selected_model = model_files[choice]

            audio_path = input(
                "\nCaminho do arquivo de √°udio: ").strip().strip('"')

            if not Path(audio_path).exists():
                print("‚ùå Arquivo n√£o encontrado!")
                return

            print(f"\nüîç Analisando: {Path(audio_path).name}")
            print(f"üìä Modelo: {selected_model.stem}")

            try:
                result = self.context.detection_service.detect_deepfake(
                    audio_path, selected_model.stem)

                if result.status.name == "SUCCESS":
                    prediction = result.data
                    confidence = prediction.get('confidence', 0)
                    is_fake = prediction.get('is_deepfake', False)

                    print(f"\nüìä Resultado da An√°lise:")
                    print(
                        f"   üéØ Classifica√ß√£o: {
                            'üö® DEEPFAKE' if is_fake else '‚úÖ REAL'}")
                    print(f"   üìà Confian√ßa: {confidence:.2%}")

                    if confidence > 0.8:
                        print(f"   ‚úÖ Alta confian√ßa")
                    elif confidence > 0.6:
                        print(f"   ‚ö†Ô∏è  Confian√ßa moderada")
                    else:
                        print(f"   ‚ùå Baixa confian√ßa")
                else:
                    print(f"‚ùå Erro na an√°lise: {result.message}")

            except Exception as e:
                print(f"‚ùå Erro ao analisar √°udio: {e}")
                self.context.logger.error(f"Erro na infer√™ncia: {e}")

        except ValueError:
            print("‚ùå Entrada inv√°lida!")

    def analyze_batch_audio(self):
        """Analisa m√∫ltiplos arquivos de √°udio."""
        print("\nüìÅ An√°lise em Lote")
        print("‚ö†Ô∏è  Funcionalidade em desenvolvimento.")
