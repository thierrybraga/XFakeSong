# Deploy no Hugging Face Spaces

O XfakeSong foi projetado para ser facilmente implantado no [Hugging Face Spaces](https://huggingface.co/spaces), uma plataforma popular para hospedar demonstraÃ§Ãµes de Machine Learning.

Este guia cobre o processo de deploy usando tanto o **Gradio SDK** (padrÃ£o) quanto **Docker** customizado, alÃ©m de explicar como consumir a API da aplicaÃ§Ã£o hospedada.

## 1. PrÃ©-requisitos

*   Uma conta no [Hugging Face](https://huggingface.co/join).
*   Um novo Space criado (visibilidade PÃºblica ou Privada).
*   (Opcional) Git instalado localmente.

---

## 2. MÃ©todo 1: Gradio SDK (Recomendado)

O projeto jÃ¡ possui a configuraÃ§Ã£o necessÃ¡ria (`README.md` metadata) para ser detectado automaticamente como uma aplicaÃ§Ã£o Gradio.

### Passo 1: ConfiguraÃ§Ã£o do Metadata
O arquivo `README.md` na raiz do projeto jÃ¡ contÃ©m o bloco YAML necessÃ¡rio:

```yaml
---
title: XfakeSong
emoji: ðŸ›¡ï¸
colorFrom: blue
colorTo: slate
sdk: gradio
sdk_version: 4.19.2
app_file: app.py
pinned: false
license: mit
---
```

### Passo 2: DependÃªncias
Certifique-se de que o arquivo `requirements.txt` na raiz contÃ©m todas as bibliotecas necessÃ¡rias. O Hugging Face instalarÃ¡ automaticamente tudo listado ali.

> **Nota:** Bibliotecas de sistema (como `ffmpeg`) jÃ¡ estÃ£o prÃ©-instaladas no ambiente padrÃ£o do Gradio SDK. Se precisar de libs exÃ³ticas, use o MÃ©todo 2 (Docker).

### Passo 3: Deploy via Git
VocÃª pode fazer push do cÃ³digo diretamente para o repositÃ³rio do seu Space.

1.  Clone o repositÃ³rio do seu Space:
    ```bash
    git clone https://huggingface.co/spaces/SEU_USUARIO/NOME_DO_SPACE
    ```
2.  Copie os arquivos do projeto para dentro da pasta clonada (excluindo `.git` original).
3.  FaÃ§a o push:
    ```bash
    git add .
    git commit -m "Deploy inicial XfakeSong"
    git push
    ```

### Passo 4: SincronizaÃ§Ã£o AutomÃ¡tica (GitHub Actions)
Para manter seu Space sincronizado com o GitHub automaticamente, crie um workflow em `.github/workflows/sync_to_hub.yml`:

```yaml
name: Sync to Hugging Face hub
on:
  push:
    branches: [main]

  # Permite execuÃ§Ã£o manual
  workflow_dispatch:

jobs:
  sync-to-hub:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          lfs: true
      - name: Push to hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: git push https://SEU_USUARIO:$HF_TOKEN@huggingface.co/spaces/SEU_USUARIO/NOME_DO_SPACE main
```
*Configure o segredo `HF_TOKEN` nas configuraÃ§Ãµes do seu repositÃ³rio GitHub.*

---

## 3. MÃ©todo 2: Docker (AvanÃ§ado)

Se precisar de controle total sobre o sistema operacional (ex: versÃµes especÃ­ficas do FFmpeg, drivers CUDA customizados), use o Docker.

### Passo 1: Ajustar Metadata
Altere o `sdk` no `README.md`:

```yaml
sdk: docker
app_port: 7860
```

### Passo 2: Dockerfile
O projeto jÃ¡ inclui um `Dockerfile` otimizado. O Hugging Face construirÃ¡ a imagem automaticamente baseada nele.

**Pontos de AtenÃ§Ã£o:**
*   **PermissÃµes:** O HF Spaces roda containers com um usuÃ¡rio nÃ£o-root (ID 1000). O Dockerfile atual jÃ¡ configura o usuÃ¡rio `appuser` corretamente.
*   **Cache:** O diretÃ³rio `/app/models` e `/app/data` deve ter permissÃµes de escrita se a aplicaÃ§Ã£o precisar salvar arquivos em tempo de execuÃ§Ã£o (embora o armazenamento seja efÃªmero, a menos que use Persistent Storage).

---

## 4. Acessando a Interface e API

Uma vez implantado, seu Space estarÃ¡ acessÃ­vel em `https://huggingface.co/spaces/SEU_USUARIO/NOME_DO_SPACE`.

### Interface Web (GUI)
A interface Gradio completa estarÃ¡ disponÃ­vel no navegador, permitindo:
*   Upload de Ã¡udio para detecÃ§Ã£o.
*   VisualizaÃ§Ã£o de espectrogramas.
*   Treinamento de modelos (se hardware permitir).

### Acesso via API (Gradio Client)
O Gradio gera automaticamente uma API RESTful para sua aplicaÃ§Ã£o. VocÃª pode interagir com ela programaticamente usando a biblioteca `gradio_client`.

#### InstalaÃ§Ã£o
```bash
pip install gradio_client
```

#### Exemplo de Uso (Python)
```python
from gradio_client import Client

# Conectar ao Space (substitua pelo seu)
client = Client("thier/XfakeSong")

# Fazer prediÃ§Ã£o (exemplo para aba de detecÃ§Ã£o)
# Os endpoints podem variar. Verifique clicando em "Use via API" no rodapÃ© do Space.
result = client.predict(
		"caminho/para/audio.wav", # Arquivo de Ã¡udio
		api_name="/predict"       # Nome do endpoint
)

print(result)
```

### Endpoints DisponÃ­veis
Para listar todos os endpoints disponÃ­veis na sua aplicaÃ§Ã£o:
```python
client.view_api()
```
Isso retornarÃ¡ uma lista como:
```text
Client.predict() Usage Info
---------------------------
Named API endpoints: 1

 - predict(audio, api_name="/predict") -> value_0
    Parameters:
     - [Audio] audio: filepath or URL to file
    Returns:
     - [JSON] value_0: Result JSON
```

---

## 5. VariÃ¡veis de Ambiente e Segredos

Se sua aplicaÃ§Ã£o precisar de chaves de API ou configuraÃ§Ãµes sensÃ­veis:

1.  VÃ¡ em **Settings** no seu Space.
2.  DesÃ§a atÃ© **Variables and secrets**.
3.  Adicione as variÃ¡veis (ex: `DB_CONNECTION_STRING`, `JWT_SECRET`).
4.  No cÃ³digo Python, acesse via `os.environ`:

```python
import os
secret_key = os.environ.get("JWT_SECRET")
```

## 6. Hardware e Performance

*   **CPU Basic (GrÃ¡tis):** 2 vCPU, 16GB RAM. Bom para inferÃªncia de modelos leves (SVM, RawNet2).
*   **GPU (Pago):** T4, A10G, A100. NecessÃ¡rio para treinamento rÃ¡pido ou inferÃªncia de Transformers pesados (WavLM, HuBERT).

Para alterar o hardware, vÃ¡ em **Settings > Hardware** no painel do Space.
